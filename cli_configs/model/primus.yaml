_target_: models.eva_mae_openneuro.Eva_MAE
embed_dim: 864
patch_embed_size: [8,8,8]
depth: 16
num_heads: 12
num_reg_tokens: 0
use_rot_pos_emb: True
use_abs_pos_emb: True
mlp_ratio: 2.66666667
drop_path_rate: 0
drop_path_scale: True
patch_drop_rate: 0.0
proj_drop_rate: 0.0
attn_drop_rate: 0.2
rope_kwargs: null
pretrained: True
chpt_path: null
classification_head_dropout: 0.2
token_aggregation_method: avg_no_cls_token
pretraining_input_shape_mismatch: interpolate
finetune_method: full
load_cls_token: False
cls_token_available: False