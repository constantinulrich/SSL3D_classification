# @package _global_
data:
  module:
    _target_: datasets.alsdataset.ALSDataModule
    name: als_dataset
    data_root_dir: ${data_dir}
    batch_size: 2
    train_transforms:
      _target_: augmentation.policies.batchgenerators.get_training_transforms
      patch_size: ${data.patch_size}
      rotation_for_DA: 0.523599
      mirror_axes: [0,1,2]
      do_dummy_2d_data_aug: False
    test_transforms: null
  cv:
    k: 3

  num_classes: 2
  patch_size: [160, 160, 160] # adjust to fix later

model:
  task: 'Classification'
  cifar_size: False
  input_channels: 1
  input_dim: 3
  input_shape: ${data.patch_size}
  optimizer: AdamW
  lr: 0.0001
  warmstart: 20
  weight_decay: 1e-2
  label_smoothing: 0.2


trainer:
  logger:
    project: als_dataset
  accumulate_grad_batches: 48
  max_epochs: 200
  sync_batchnorm: True

metrics:
  - 'f1'
  - 'balanced_acc'
  - 'ap'
  - 'auroc'